{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.model_pruning.python import pruning\n",
    "from tensorflow.contrib.model_pruning.python.layers import layers\n",
    "import keras\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "epochs_prune = 5\n",
    "batch_size = 250 # Entire training set\n",
    "model_path_unpruned = \"Model_Saves/Unpruned{}.ckpt\"\n",
    "model_path_pruned = \"Model_Saves/Pruned{}.ckpt\"\n",
    "NUM_CLASS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading numpy\n",
      "Loading numpy\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "#Load Dataset\n",
    "X_train0, y_train = prepare_dataset(data_dir, 'train')\n",
    "X_test0, y_test = prepare_dataset(data_dir, 'test')\n",
    "t = int(time.time())\n",
    "\n",
    "#Normalizing\n",
    "mean = np.mean(X_train0,axis=(0,1,2,3))\n",
    "std = np.std(X_train0,axis=(0,1,2,3))\n",
    "np.save('mean',mean)\n",
    "np.save('std',std)\n",
    "X_train = z_normalization(X_train0, mean, std)\n",
    "X_test = z_normalization(X_test0, mean, std)\n",
    "\n",
    "#Labels to binary\n",
    "y_train_binary = keras.utils.to_categorical(y_train,num_classes)\n",
    "y_test_binary = keras.utils.to_categorical(y_test,num_classes)\n",
    "\n",
    "batches = int(len(X_train) / batch_size)\n",
    "batches_test = int(len(X_test) / batch_size)\n",
    "print(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_batch(dataset, labels, batch_size):\n",
    "    N = dataset.shape[0]\n",
    "    indices = np.random.randint(N, size=batch_size)\n",
    "    x_epoch = dataset[indices]\n",
    "    y_epoch = labels[indices]\n",
    "    return x_epoch, y_epoch\n",
    "\n",
    "def test_batch(dataset, labels, batch_size):\n",
    "    for index, offset in enumerate(range(0, dataset.shape[0], batch_size)):\n",
    "        x_epoch, y_epoch = np.array(dataset[offset: offset + batch_size,:]), np.array(labels[offset: offset +  batch_size])\n",
    "    return x_epoch, y_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "image = tf.placeholder(name='images', dtype=tf.float32, shape=[None, 32, 32, 3])\n",
    "label = tf.placeholder(name='fine_labels', dtype=tf.int32, shape=[None, 10])\n",
    "\n",
    "# # Define the model\n",
    "# layer1 = layers.masked_fully_connected(image, 300)\n",
    "# layer2 = layers.masked_fully_connected(layer1, 300)\n",
    "# logits = layers.masked_fully_connected(layer2, 10)\n",
    "\n",
    "# Define the model\n",
    "# layer1 = layers.masked_conv2d(image, 300, kernel_size=2)\n",
    "# layer2 = layers.masked_conv2d(layer1, 300, kernel_size=2)\n",
    "# logits = layers.masked_fully_connected(layer2, 10)\n",
    "\n",
    "_=image\n",
    "_ = layers.masked_conv2d(_, 96, (3, 3), 1, 'SAME')\n",
    "_ = tf.layers.batch_normalization(_, name='norm1-1')\n",
    "_ = layers.masked_conv2d(_, 96, (3, 3), 1, 'SAME')\n",
    "_ = tf.layers.batch_normalization(_, name='norm1-2')\n",
    "_ = tf.layers.max_pooling2d(_, (3, 3), 2, 'SAME',name='pool1')\n",
    "_ = layers.masked_conv2d(_, 192, (3, 3), 1, 'SAME')\n",
    "_ = tf.layers.batch_normalization(_, name='norm2-1')\n",
    "_ = layers.masked_conv2d(_, 192, (3, 3), 1, 'SAME')\n",
    "_ = tf.layers.batch_normalization(_, name='norm2-2')\n",
    "_ = tf.layers.max_pooling2d(_, (3, 3), 2, 'SAME', name='pool2')\n",
    "_ = layers.masked_conv2d(_, 192, (3, 3), 1, 'VALID')\n",
    "_ = tf.layers.batch_normalization(_, name='norm3')\n",
    "_ = layers.masked_conv2d(_, 192, (1, 1), 1)\n",
    "_ = tf.layers.batch_normalization(_, name='norm4')\n",
    "_ = layers.masked_conv2d(_, 10, (1, 1), 1)\n",
    "_ = tf.layers.batch_normalization(_, name='norm5')\n",
    "_ = tf.layers.average_pooling2d(_, (6,6), 1, name='avg_pool')\n",
    "y = _\n",
    "logits = tf.reshape(y,[tf.shape(y)[0],10])\n",
    "\n",
    "\n",
    "# Create global step variable (needed for pruning)\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "reset_global_step_op = tf.assign(global_step, 0)\n",
    "\n",
    "# Loss function\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(label, logits)\n",
    "\n",
    "# Training op, the global step is critical here, make sure it matches the one used in pruning later\n",
    "# running this operation increments the global_step\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss, global_step=global_step)\n",
    "# train_op = tf.train.GradientDescentOptimizer(\n",
    "#         learning_rate=0.001,\n",
    "#         # beta1=0.9,\n",
    "#         # beta2=0.999,\n",
    "#         # epsilon=1e-08,\n",
    "#         use_locking=False,\n",
    "#         name='GD'\n",
    "#     ).minimize(loss, global_step=global_step)\n",
    "\n",
    "# Accuracy ops\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(label, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "accuracy_5 = tf.reduce_mean(tf.cast(tf.nn.in_top_k(predictions=logits, targets=tf.argmax(label, 1), k=5), tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning Hyperparameters: [('begin_pruning_step', 0), ('block_height', 1), ('block_pooling_function', 'AVG'), ('block_width', 1), ('do_not_prune', ['']), ('end_pruning_step', -1), ('initial_sparsity', 0), ('name', 'model_pruning'), ('nbins', 256), ('pruning_frequency', 10), ('sparsity_function_begin_step', 0), ('sparsity_function_end_step', 100), ('sparsity_function_exponent', 3), ('target_sparsity', 0.5), ('threshold_decay', 0.9), ('use_tpu', False)]\n",
      "INFO:tensorflow:Updating masks.\n"
     ]
    }
   ],
   "source": [
    "# Get, Print, and Edit Pruning Hyperparameters\n",
    "pruning_hparams = pruning.get_pruning_hparams()\n",
    "print(\"Pruning Hyperparameters:\", pruning_hparams)\n",
    "\n",
    "# Change hyperparameters to meet our needs\n",
    "pruning_hparams.begin_pruning_step = 0\n",
    "pruning_hparams.end_pruning_step = 250\n",
    "pruning_hparams.pruning_frequency = 1\n",
    "pruning_hparams.sparsity_function_end_step = 250\n",
    "pruning_hparams.target_sparsity = .5\n",
    "\n",
    "# Create a pruning object using the pruning specification, sparsity seems to have priority over the hparam\n",
    "p = pruning.Pruning(pruning_hparams, global_step=global_step) #sparsity=.5)\n",
    "prune_op = p.conditional_mask_update_op()\n",
    "\n",
    "# Create a saver for writing training checkpoints.\n",
    "saver = tf.train.Saver()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un-pruned model step 0 test accuracy 0.3486\n",
      "Un-pruned model step 0 test top5-accuracy 0.8616\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Un-pruned model step 5 test accuracy 0.7723\n",
      "Un-pruned model step 5 test top5-accuracy 0.9859\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Un-pruned model step 10 test accuracy 0.8091\n",
      "Un-pruned model step 10 test top5-accuracy 0.9853\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "Un-pruned model step 15 test accuracy 0.8205\n",
      "Un-pruned model step 15 test top5-accuracy 0.9906\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "Un-pruned model step 20 test accuracy 0.8163\n",
      "Un-pruned model step 20 test top5-accuracy 0.9885\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "Un-pruned model step 25 test accuracy 0.8299\n",
      "Un-pruned model step 25 test top5-accuracy 0.9915\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "Un-pruned model step 30 test accuracy 0.826\n",
      "Un-pruned model step 30 test top5-accuracy 0.9891\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "Un-pruned model step 35 test accuracy 0.8328\n",
      "Un-pruned model step 35 test top5-accuracy 0.9894\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "Un-pruned model step 40 test accuracy 0.8321\n",
      "Un-pruned model step 40 test top5-accuracy 0.9888\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "Un-pruned model step 45 test accuracy 0.8287\n",
      "Un-pruned model step 45 test top5-accuracy 0.9907\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "Pre-Pruning accuracy: 0.1657400006055832\n",
      "Sparsity of layers (should be 0) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "WARNING:tensorflow:From c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "INFO:tensorflow:Restoring parameters from Model_Saves/Unpruned0.ckpt\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for Model_Saves/Unpruned0.ckpt\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\t [[Node: save/RestoreV2/_353 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_84_save/RestoreV2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\asyncio\\events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-c184818322e4>\", line 17, in <module>\n    saver = tf.train.Saver()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1284, in __init__\n    self.build()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1296, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1333, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 781, in _build_internal\n    restore_sequentially, reshape)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 400, in _AddRestoreOps\n    restore_sequentially)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 832, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1546, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for Model_Saves/Unpruned0.ckpt\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\t [[Node: save/RestoreV2/_353 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_84_save/RestoreV2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for Model_Saves/Unpruned0.ckpt\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\t [[Node: save/RestoreV2/_353 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_84_save/RestoreV2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-60a1f10065c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# Resets the session and restores the saved model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize_all_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_path_unpruned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc_print\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m# Reset the global step counter and begin pruning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1766\u001b[0m         \u001b[0mshould_reraise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1767\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mshould_reraise\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1768\u001b[1;33m         \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexception_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception_traceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1769\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mexception_traceback\u001b[0m  \u001b[1;31m# avoid reference cycles\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1770\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1750\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1751\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[1;32m-> 1752\u001b[1;33m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[0;32m   1753\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1754\u001b[0m       \u001b[0mexception_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception_traceback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for Model_Saves/Unpruned0.ckpt\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\t [[Node: save/RestoreV2/_353 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_84_save/RestoreV2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\asyncio\\events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-c184818322e4>\", line 17, in <module>\n    saver = tf.train.Saver()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1284, in __init__\n    self.build()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1296, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1333, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 781, in _build_internal\n    restore_sequentially, reshape)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 400, in _AddRestoreOps\n    restore_sequentially)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 832, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1546, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for Model_Saves/Unpruned0.ckpt\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\t [[Node: save/RestoreV2/_353 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_84_save/RestoreV2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    # Uncomment the following if you don't have a trained model yet\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Train the model before pruning (optional)\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(batches):\n",
    "            batch_xs, batch_ys = sample_batch(X_train, y_train_binary, batch_size)\n",
    "            sess.run(train_op, feed_dict={image: batch_xs, label: batch_ys})\n",
    "\n",
    "        # Calculate Test Accuracy every 10 epochs\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            acc_print = 0\n",
    "            acc_print_5 = 0\n",
    "            for index, offset in enumerate(range(0, X_test.shape[0], batch_size)):\n",
    "                batch_xt = np.array(X_test[offset: offset + batch_size,:]) \n",
    "                batch_yt = np.array(y_test_binary[offset: offset +  batch_size])\n",
    "#             for batch in range(batches_test):\n",
    "#                 batch_xt, batch_yt = test_batch(X_test, y_test_binary, batch_size)\n",
    "                acc_print += sess.run(accuracy, feed_dict={image: batch_xt, label: batch_yt})\n",
    "                acc_print_5 += sess.run(accuracy_5, feed_dict={image: batch_xt, label: batch_yt})\n",
    "            print(\"Un-pruned model step %d test accuracy %g\" % (epoch, acc_print/batches_test))\n",
    "            print(\"Un-pruned model step %d test top5-accuracy %g\" % (epoch, acc_print_5/batches_test))\n",
    "            \n",
    "            # Saves the model before pruning\n",
    "            saver.save(sess, model_path_unpruned.format(epoch))\n",
    "        print(epoch)\n",
    "            \n",
    "        \n",
    "    print(\"Top-1 Pre-Pruning accuracy:\", acc_print/batches_test)\n",
    "    print(\"Top-5 Pre-Pruning accuracy:\", acc_print_5/batches_test)\n",
    "    print(\"Sparsity of layers (should be 0)\", sess.run(tf.contrib.model_pruning.get_weight_sparsity()))\n",
    "\n",
    "    \n",
    "\n",
    "    # Resets the session and restores the saved model\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    saver.restore(sess, model_path_unpruned.format(int(acc_print/batches)))\n",
    "\n",
    "    # Reset the global step counter and begin pruning\n",
    "    sess.run(reset_global_step_op)\n",
    "    for epoch in range(epochs_prune):\n",
    "        for batch in range(batches):\n",
    "            batch_xs, batch_ys = sample_batch(X_train, y_train_binary, batch_size)\n",
    "            # Prune and retrain\n",
    "            sess.run(prune_op)\n",
    "            sess.run(train_op, feed_dict={image: batch_xs, label: batch_ys})\n",
    "\n",
    "        # Calculate Test Accuracy every 10 epochs\n",
    "        if epoch % 1 == 0:\n",
    "            acc_print = 0\n",
    "            acc_print_5 = 0\n",
    "            for batch in range(batches):\n",
    "                batch_xt, batch_yt = sample_batch(X_test, y_test_binary, batch_size)\n",
    "                acc_print += sess.run(accuracy, feed_dict={image: batch_xt, label: batch_yt})\n",
    "            \n",
    "            print(\"Pruned model step %d test accuracy %g\" % (epoch, acc_print/batches))\n",
    "            print(\"Weight sparsities:\", sess.run(tf.contrib.model_pruning.get_weight_sparsity()))\n",
    "        print(epoch) \n",
    "        \n",
    "           # acc_print = sess.run(accuracy, feed_dict={image: mnist.test.images, label: mnist.test.labels})\n",
    "\n",
    "    # Saves the model after pruning\n",
    "    saver.save(sess, model_path_pruned.format(int(acc_print/batches)))\n",
    "\n",
    "    # Print final accuracy\n",
    "    #acc_print = sess.run(accuracy, feed_dict={image: mnist.test.images, label: mnist.test.labels})\n",
    "    print(\"Final accuracy:\", acc_print/batches)\n",
    "    print(\"Final sparsity by layer (should be 0)\", sess.run(tf.contrib.model_pruning.get_weight_sparsity()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "batch_size = 512 # Entire training set\n",
    "model_path_unpruned = \"Model_Saves/Unpruned.ckpt\"\n",
    "model_path_pruned = \"Model_Saves/Pruned.ckpt\"\n",
    "NUM_CLASS = 10\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Import dataset\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "batches = int(len(mnist.train.images) / batch_size)\n",
    "\n",
    "# Define Placeholders\n",
    "# image = tf.placeholder(tf.float32, [None, 28,28])\n",
    "# label = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "image = tf.placeholder(name='images', dtype=tf.float32, shape=[None, 28, 28, 1])\n",
    "label = tf.placeholder(name='fine_labels', dtype=tf.int32, shape=[None,10])\n",
    "\n",
    "# # Define the model\n",
    "# layer1 = layers.masked_fully_connected(image, 300)\n",
    "# layer2 = layers.masked_fully_connected(layer1, 300)\n",
    "# logits = layers.masked_fully_connected(layer2, 10)\n",
    "\n",
    "# Define the model\n",
    "# layer1 = layers.masked_conv2d(image, 300, kernel_size=2)\n",
    "# layer2 = layers.masked_conv2d(layer1, 300, kernel_size=2)\n",
    "# logits = layers.masked_fully_connected(layer2, 10)\n",
    "\n",
    "_=image\n",
    "_ = layers.masked_conv2d(_, 96, (3, 3), 1, 'SAME')\n",
    "_ = tf.layers.batch_normalization(_, name='norm1-1')\n",
    "_ = layers.masked_conv2d(_, 96, (3, 3), 1, 'SAME')\n",
    "_ = tf.layers.batch_normalization(_, name='norm1-2')\n",
    "_ = tf.layers.max_pooling2d(_, (3, 3), 2, 'SAME',name='pool1')\n",
    "_ = layers.masked_conv2d(_, 192, (3, 3), 1, 'SAME')\n",
    "_ = tf.layers.batch_normalization(_, name='norm2-1')\n",
    "_ = layers.masked_conv2d(_, 192, (3, 3), 1, 'SAME')\n",
    "_ = tf.layers.batch_normalization(_, name='norm2-2')\n",
    "_ = tf.layers.max_pooling2d(_, (3, 3), 2, 'SAME', name='pool2')\n",
    "_ = layers.masked_conv2d(_, 192, (3, 3), 1, 'VALID')\n",
    "_ = tf.layers.batch_normalization(_, name='norm3')\n",
    "_ = layers.masked_conv2d(_, 192, (1, 1), 1)\n",
    "_ = tf.layers.batch_normalization(_, name='norm4')\n",
    "_ = layers.masked_conv2d(_, 10, (1, 1), 1)\n",
    "_ = tf.layers.batch_normalization(_, name='norm5')\n",
    "_ = tf.layers.average_pooling2d(_, (5,5), 1, name='avg_pool')\n",
    "y = _\n",
    "logits = tf.reshape(y,[tf.shape(y)[0],10])\n",
    "\n",
    "\n",
    "# Create global step variable (needed for pruning)\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "reset_global_step_op = tf.assign(global_step, 0)\n",
    "\n",
    "# Loss function\n",
    "#loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=label))\n",
    "#loss = tf.losses.softmax_cross_entropy(tf.one_hot(label, NUM_CLASS), logits)\n",
    "loss = tf.losses.softmax_cross_entropy(label, logits)\n",
    "\n",
    "# Training op, the global step is critical here, make sure it matches the one used in pruning later\n",
    "# running this operation increments the global_step\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss, global_step=global_step)\n",
    "\n",
    "# Accuracy ops\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(label, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get, Print, and Edit Pruning Hyperparameters\n",
    "pruning_hparams = pruning.get_pruning_hparams()\n",
    "print(\"Pruning Hyperparameters:\", pruning_hparams)\n",
    "\n",
    "# Change hyperparameters to meet our needs\n",
    "pruning_hparams.begin_pruning_step = 0\n",
    "pruning_hparams.end_pruning_step = 250\n",
    "pruning_hparams.pruning_frequency = 1\n",
    "pruning_hparams.sparsity_function_end_step = 250\n",
    "pruning_hparams.target_sparsity = .5\n",
    "\n",
    "# Create a pruning object using the pruning specification, sparsity seems to have priority over the hparam\n",
    "p = pruning.Pruning(pruning_hparams, global_step=global_step) #sparsity=.5)\n",
    "prune_op = p.conditional_mask_update_op()\n",
    "\n",
    "# Create a saver for writing training checkpoints.\n",
    "saver = tf.train.Saver()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    # Uncomment the following if you don't have a trained model yet\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Train the model before pruning (optional)\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(batches):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            #print(batch_xs.shape)\n",
    "            batch_xs = batch_xs.reshape(-1,28,28,1)\n",
    "            sess.run(train_op, feed_dict={image: batch_xs, label: batch_ys})\n",
    "\n",
    "        # Calculate Test Accuracy every 10 epochs\n",
    "        if epoch % 1 == 0:\n",
    "            acc_print = 0\n",
    "            for batch in range(batches):\n",
    "                batch_xt, batch_yt = mnist.test.next_batch(batch_size)\n",
    "                #print(batch_xt.shape)\n",
    "                batch_xt = batch_xt.reshape(-1,28,28,1)\n",
    "                acc_print += sess.run(accuracy, feed_dict={image: batch_xt, label: batch_yt})\n",
    "            print(\"Un-pruned model step %d test accuracy %g\" % (epoch, acc_print/batches))\n",
    "        print(epoch)\n",
    "    \n",
    "    # Saves the model before pruning\n",
    "    saver.save(sess, model_path_unpruned)\n",
    "    \n",
    "    acc_print = sess.run(accuracy, feed_dict={image: mnist.test.images.reshape(-1,28,28,1), label: mnist.test.labels})\n",
    "    print(\"Pre-Pruning accuracy:\", acc_print)\n",
    "    print(\"Sparsity of layers (should be 0)\", sess.run(tf.contrib.model_pruning.get_weight_sparsity()))\n",
    "\n",
    "    \n",
    "\n",
    "    # Resets the session and restores the saved model\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    saver.restore(sess, model_path_unpruned)\n",
    "\n",
    "    # Reset the global step counter and begin pruning\n",
    "    sess.run(reset_global_step_op)\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(batches):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            batch_xs = batch_xs.reshape(-1,28,28,1)\n",
    "            # Prune and retrain\n",
    "            sess.run(prune_op)\n",
    "            sess.run(train_op, feed_dict={image: batch_xs, label: batch_ys})\n",
    "\n",
    "        # Calculate Test Accuracy every 10 epochs\n",
    "        if epoch % 1 == 0:\n",
    "            acc_print = 0\n",
    "            for batch in range(batches):\n",
    "                batch_xt, batch_yt = mnist.test.next_batch(batch_size)\n",
    "                #print(batch_xt.shape)\n",
    "                batch_xt = batch_xt.reshape(-1,28,28,1)\n",
    "                acc_print += sess.run(accuracy, feed_dict={image: batch_xt, label: batch_yt})\n",
    "            \n",
    "            print(\"Pruned model step %d test accuracy %g\" % (epoch, acc_print/batches))\n",
    "            print(\"Weight sparsities:\", sess.run(tf.contrib.model_pruning.get_weight_sparsity()))\n",
    "        print(epoch) \n",
    "        \n",
    "           # acc_print = sess.run(accuracy, feed_dict={image: mnist.test.images, label: mnist.test.labels})\n",
    "\n",
    "    # Saves the model after pruning\n",
    "    saver.save(sess, model_path_pruned)\n",
    "\n",
    "    # Print final accuracy\n",
    "    #acc_print = sess.run(accuracy, feed_dict={image: mnist.test.images, label: mnist.test.labels})\n",
    "    print(\"Final accuracy:\", acc_print)\n",
    "    print(\"Final sparsity by layer (should be 0)\", sess.run(tf.contrib.model_pruning.get_weight_sparsity()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
